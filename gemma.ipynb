{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a602f609-d8b0-4886-b2aa-2b94ea1c9699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sick/code/llm_study/llm_venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|███████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>Write me a poem about Machine Learning.\n",
      "\n",
      "Machines, they weave and they learn,\n",
      "From the data, they discern.\n",
      "Algorithms, a symphony,\n",
      "Unleash the power of the machine.\n",
      "\n",
      "With each iteration, they grow,\n",
      "A tapestry of insights they sow.\n",
      "From the past, they learn and they adapt,\n",
      "A never-ending, ever-fast.\n",
      "\n",
      "The future holds mysteries untold,\n",
      "Where machines will shape our world.\n",
      "They will heal, they will fight, they will play,\n",
      "A symphony of the digital day.\n",
      "\n",
      "So let the machines learn and let them soar,\n",
      "For the future is here, and it's here to stay.\n",
      "With a touch of humanity, a spark of care,\n",
      "We embrace the machine, and we share.<eos>\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/google/gemma-2b-it\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./gemma-2b-it\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./gemma-2b-it\")\n",
    "\n",
    "input_text = \"Write me a poem about Machine Learning.\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\",max_length=1000,truncation=True)\n",
    "\n",
    "outputs = model.generate(**input_ids,max_new_tokens=1000)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "802984b9-f517-46ea-b0e5-f9bf0fd68939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>写一首诗，表达对自然景色的喜爱。\n",
      "\n",
      "山峰巍峨，水流奔涌，\n",
      "森林茂密，鸟儿鸣叫。\n",
      "四季如画，自然如画。\n",
      "\n",
      "天际浩瀚，地平无垠，\n",
      "生命无限，万物皆生。\n",
      "自然，我的心灵，我的乐。\n",
      "\n",
      "\n",
      "**诗**\n",
      "\n",
      "山峰巍峨，水流奔涌，\n",
      "森林茂密，鸟儿鸣叫。\n",
      "四季如画，自然如画。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_text = \"写一首诗\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\",max_length=1000,truncation=True)\n",
    "\n",
    "outputs = model.generate(**input_ids,max_new_tokens=100)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e714294d-c78b-4abe-8427-dd031b2e27d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|███████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><start_of_turn>user\n",
      "写一首诗<end_of_turn>\n",
      "<start_of_turn>model\n",
      "Stars ignite the velvet night,\n",
      "A symphony of light and might.\n",
      "Moonbeams dance on whispering grass,\n",
      "A silent serenade that will last.\n",
      "\n",
      "Birdsong fills the air with joyful cheer,\n",
      "A chorus of hope and joy to share.\n",
      "Stars ignite the velvet night,\n",
      "A symphony of light and might.\n",
      "\n",
      "Clouds drift by like wispy dreams,\n",
      "A tapestry of colors, it seems.\n",
      "Stars ignite the velvet night,\n",
      "A symphony of light and might.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "dtype = torch.bfloat16\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./gemma-2b-it\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./gemma-2b-it\")\n",
    "\n",
    "chat = [\n",
    "    { \"role\": \"user\", \"content\": \"pls\" },\n",
    "    # { \"role\": \"assistant\", \"content\": \"The number of people in the world is constantly changing, as new people are born and others die. As of October 26, 2023, there are approximately 8 billion people on Earth.\" },\n",
    "    # { \"role\": \"user\", \"content\": \"how to reduce?\" }\n",
    "]\n",
    "prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "inputs = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
    "outputs = model.generate(input_ids=inputs.to(model.device),max_new_tokens=100)\n",
    "\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89870360-f021-423a-bba5-970ac135d82e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_venv",
   "language": "python",
   "name": "llm_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
